# ü¶π Re-rank retrieved results

Re-rankers are specialized models that are trained to calculate the relevance between query-document pairs. Without re-ranking the order of retrieved results is governed by the embedding model, which isn't optimized for relevance and can lead to poor LLM recall in RAG applications.

Fill in any `<CODE_BLOCK_N>` placeholders and run the cells under the **ü¶π‚Äç‚ôÄÔ∏è Re-rank retrieved results** section in the notebook to add a re-ranking stage to the RAG application.

The answers for code blocks in this section are as follows:

**CODE_BLOCK_25**

<details>
<summary>Answer</summary>
<div>
```python
rerank_model.rank(
    user_query, documents, return_documents=True, top_k=5
)
```
</div>
</details>

**CODE_BLOCK_26**

<details>
<summary>Answer</summary>
<div>
```python
"\n\n".join([d.get("text", "") for d in reranked_documents])
```
</div>
</details>