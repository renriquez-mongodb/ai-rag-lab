{"searchDocs":[{"title":"üëê Build the RAG application","type":0,"sectionRef":"#","url":"/ai-rag-lab/docs/build-rag-app/build-rag-app","content":"üëê Build the RAG application Let's create a simple RAG application that takes in a user query, retrieves contextually relevant documents from MongoDB Atlas, and passes the query and retrieved context to the Llama 3 8B Instruct model to generate an answer to the user question. Fill in any &lt;CODE_BLOCK_N&gt; placeholders and run the cells under the Step 8: Build the RAG application section in the notebook to build the RAG application. The answers for code blocks in this section are as follows: CODE_BLOCK_16 Answer vector_search(user_query) CODE_BLOCK_17 Answer create_prompt(user_query) CODE_BLOCK_18 Answer fw_client.chat.completions.create( model=model, messages=[{&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: prompt}] ) ","keywords":"","version":"Next"},{"title":"ü¶π Re-rank retrieved results","type":0,"sectionRef":"#","url":"/ai-rag-lab/docs/build-rag-app/add-reranking","content":"ü¶π Re-rank retrieved results Re-rankers are specialized models that are trained to calculate the relevance between query-document pairs. Without re-ranking the order of retrieved results is governed by the embedding model, which isn't optimized for relevance and can lead to poor LLM recall in RAG applications. Fill in any &lt;CODE_BLOCK_N&gt; placeholders and run the cells under the ü¶π‚Äç‚ôÄÔ∏è Re-rank retrieved results section in the notebook to add a re-ranking stage to the RAG application. The answers for code blocks in this section are as follows: CODE_BLOCK_19 Answer rerank_model.rank( user_query, documents, return_documents=True, top_k=5 ) ","keywords":"","version":"Next"},{"title":"ü¶π Stream responses from the RAG application","type":0,"sectionRef":"#","url":"/ai-rag-lab/docs/build-rag-app/stream-responses","content":"ü¶π Stream responses from the RAG application By default, generation results are returned once the generation is completed. Another option is to stream the results as they come, which is useful for chat use cases where the user can incrementally see results as each token is generated. Fill in any &lt;CODE_BLOCK_N&gt; placeholders and run the cells under the ü¶π‚Äç‚ôÄÔ∏è Return streaming responses section in the notebook to stream the results from your RAG application. The answers for code blocks in this section are as follows: CODE_BLOCK_20 Answer create_prompt(user_query) CODE_BLOCK_21 Answer fw_client.chat.completions.create( model=model, messages=[{&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: prompt}], stream=True ) CODE_BLOCK_22 Answer for chunk in response: if chunk.choices[0].delta.content: print(chunk.choices[0].delta.content, end=&quot;&quot;) ","keywords":"","version":"Next"},{"title":"üëê Add memory to the RAG application","type":0,"sectionRef":"#","url":"/ai-rag-lab/docs/add-memory/add-memory","content":"üëê Add memory to the RAG application In many Q&amp;A applications we want to allow the user to have a back-and-forth conversation with the LLM, meaning the application needs some sort of &quot;memory&quot; of past questions and answers, and some logic for incorporating those into its current thinking. In this section, you will retrieve chat message history from MongoDB and incorporate it in your RAG application. Fill in any &lt;CODE_BLOCK_N&gt; placeholders and run the cells under the Step 9: Add memory to the RAG application section in the notebook to add memory to the RAG application. The answers for code blocks in this section are as follows: CODE_BLOCK_23 Answer history_collection.create_index(&quot;session_id&quot;) CODE_BLOCK_24 Answer history_collection.insert_one(message) CODE_BLOCK_25 Answer history_collection.find({&quot;session_id&quot;: session_id}).sort(&quot;timestamp&quot;, 1) CODE_BLOCK_26 Answer retrieve_session_history(session_id) CODE_BLOCK_27 Answer {&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: user_query} CODE_BLOCK_28 Answer store_chat_message(session_id, &quot;user&quot;, user_query) store_chat_message(session_id, &quot;assistant&quot;, answer) ","keywords":"","version":"Next"},{"title":"üëê Setup prerequisites","type":0,"sectionRef":"#","url":"/ai-rag-lab/docs/dev-env/setup-pre-reqs","content":"üëê Setup prerequisites Replace any placeholders and run the cells under Step 1: Setup prerequisites section in the notebook.","keywords":"","version":"Next"},{"title":"üëê Setup dev environment","type":0,"sectionRef":"#","url":"/ai-rag-lab/docs/dev-env/dev-setup","content":"","keywords":"","version":"Next"},{"title":"Option 1: GitHub Codespaces‚Äã","type":1,"pageTitle":"üëê Setup dev environment","url":"/ai-rag-lab/docs/dev-env/dev-setup#option-1-github-codespaces","content":" You will be working in a Jupyter Notebook in a GitHub Codespace throughout this lab. A codespace is a cloud-hosted, containerized development environment that comes pre-configured with all the tools you need to run this lab.  Navigate to this link. You will be prompted to sign into GitHub if you haven't already. Once signed in, click the Create new codespace button to create a new codespace.    Let it run for a few seconds as it prepares your environment. It will clone the repository, prepare the container, and run the installation scripts.  In the left navigation bar of the IDE, click on the file named notebook_template.ipynb to open the Jupyter Notebook for the lab.    Next, select the Python interpreter by clicking Select Kernel at the top right of the IDE.    In the modal that appears, click Python environments... and select the recommended interpreter.      That's it! You're ready for the lab!  ","version":"Next","tagName":"h2"},{"title":"Option 2: Run locally‚Äã","type":1,"pageTitle":"üëê Setup dev environment","url":"/ai-rag-lab/docs/dev-env/dev-setup#option-2-run-locally","content":" caution During the lab, we will use GitHub Codespaces. These instructions are here just in case you can't use Codespaces or if you really, really, really want a local installation.  If you want to run the notebook locally, follow the steps below:  Clone the GitHub repo for this lab by executing the following command from the terminal:  git clone https://github.com/mongodb-developer/ai-rag-lab-notebooks.git   cd into the cloned directory:  cd ai-rag-lab-notebooks   Create and activate a Python virtual environment:  python -m venv mongodb-ai-rag-lab source mongodb-ai-rag-lab/bin/activate   Install and launch Jupyter Notebook:  pip install notebook jupyter notebook   In the browser tab that pops up, open the file named notebook_template.ipynb.   ","version":"Next","tagName":"h2"},{"title":"üëê Create an API key","type":0,"sectionRef":"#","url":"/ai-rag-lab/docs/fireworks-ai/create-api-key","content":"üëê Create an API key Once logged in, navigate to API keys under User Settings. Click the Create API Key button to create a Secure API Key. In the modal that appears, follow the steps to create an API key and when prompted, copy and paste it somewhere safe.","keywords":"","version":"Next"},{"title":"üëê Create an account","type":0,"sectionRef":"#","url":"/ai-rag-lab/docs/fireworks-ai/create-account","content":"üëê Create an account In this lab, we will use the Llama 3 8B Instruct model hosted by Fireworks AI. The easiest way to use this model is via the Fireworks API. But first, you will need to create a Fireworks account. tip If you already have an account, you can skip the following steps and continue the workshop from create an API key Start by navigating to the Fireworks AI homepage and click the purple Get Started Free button to create an account. Click Login With Google and authenticate with your Google account.","keywords":"","version":"Next"},{"title":"Introduction","type":0,"sectionRef":"#","url":"/ai-rag-lab/docs/intro","content":"Introduction Lab goals\tLearn how to build a RAG application from scratchWhat you'll learn\tWhat is RAG Components of a RAG system Perform semantic search queries using Mongo Atlas Vector Search Build a RAG system using MongoDB Atlas and Fireworks AI Add memory to your RAG application Time to complete\t90 mins In the navigation bar and in some pages, you will notice some icons. Here is their meaning: Icon\tMeaning\tDescriptionüìò\tLecture material\tIf you are following along in an instructor-led session, they probably have covered this already. üëê\tHands-on content\tGet ready to do some hands-on work. You should follow these steps. üìö\tDocumentation\tReference documentation for hands-on portions of the lab. ü¶π\tAdvanced content\tThis content isn't covered during the lab, but if you're interested in learning more, you can check it out.","keywords":"","version":"Next"},{"title":"üìò Running Jupyter Notebooks","type":0,"sectionRef":"#","url":"/ai-rag-lab/docs/dev-env/jupyter-notebooks","content":"üìò Running Jupyter Notebooks Jupyter Notebooks is an interactive Python environment. Cells in a Jupyter notebook are a modular unit of code or text that you can execute and view outputs for. To run a cell in a Jupyter notebook, hover over it and click the Run icon that appears against the cell. When a cell is running, you will see a loading spinner in the bottom left corner of the cell. When a cell is finished running successfully, you will see a green check mark appear in the bottom left corner of the cell. If an error occurred while running a cell, you will see a red cross appear in the bottom left corner of the cell, and also an error traceback after the cell. To fix errors, you may need to update previous cells. If you do, re-run all the cells following the one(s) you updated. To interrupt a running cell, click the Stop icon that you see against the cell while it is running. warning The UI might differ slightly if you are running Jupyter Notebooks in a different IDE. Refer to the appropriate documentation if running the notebook in a different environment.","keywords":"","version":"Next"},{"title":"üëê Create your account","type":0,"sectionRef":"#","url":"/ai-rag-lab/docs/mongodb-atlas/create-account","content":"","keywords":"","version":"Next"},{"title":"Sign up for MongoDB Atlas‚Äã","type":1,"pageTitle":"üëê Create your account","url":"/ai-rag-lab/docs/mongodb-atlas/create-account#sign-up-for-mongodb-atlas","content":" Start by going to the MongoDB website and creating your account.  tip Creating a MongoDB Atlas account is free and does not require a credit card.  You will be greeted by a form similar to the one below.    info If you are doing this lab at an event, you should use the same email address you used to register for the event.  Complete the form and click the Create Your Atlas Account button.  ","version":"Next","tagName":"h2"},{"title":"Verify your email address‚Äã","type":1,"pageTitle":"üëê Create your account","url":"/ai-rag-lab/docs/mongodb-atlas/create-account#verify-your-email-address","content":" You will receive an email from MongoDB asking you to verify your email address. Click the link in the email to verify your email address.    caution If you haven't received the email within two minutes, check your spam folder.  ","version":"Next","tagName":"h2"},{"title":"Finish the onboarding‚Äã","type":1,"pageTitle":"üëê Create your account","url":"/ai-rag-lab/docs/mongodb-atlas/create-account#finish-the-onboarding","content":" You will be redirected to the MongoDB Atlas onboarding wizard. Fill in the form and click Finish to continue. ","version":"Next","tagName":"h2"},{"title":"üëê Deploy a database cluster","type":0,"sectionRef":"#","url":"/ai-rag-lab/docs/mongodb-atlas/create-cluster","content":"","keywords":"","version":"Next"},{"title":"Security quickstart‚Äã","type":1,"pageTitle":"üëê Deploy a database cluster","url":"/ai-rag-lab/docs/mongodb-atlas/create-cluster#security-quickstart","content":" By default, your MongoDB Atlas deployment is completely locked-down. You need to configure the network settings and create a user to access your database.  While your deployment is being provisioned, you will see the security quickstart dialog.  ","version":"Next","tagName":"h2"},{"title":"Network access‚Äã","type":1,"pageTitle":"üëê Deploy a database cluster","url":"/ai-rag-lab/docs/mongodb-atlas/create-cluster#network-access","content":" First, you should Allow Access from Anywhere. You will see a field pre-populated with the IP address 0.0.0.0/0. This means that you can connect to your database from any IP address including the virtual environment you will use for this lab. Click Add IP Address to add this IP address to the network allowlist.  caution It is dangerous to expose your database to the entire world. Never do this is a real production environment.  ","version":"Next","tagName":"h3"},{"title":"Database user‚Äã","type":1,"pageTitle":"üëê Deploy a database cluster","url":"/ai-rag-lab/docs/mongodb-atlas/create-cluster#database-user","content":" Next, you need to create a database user. Pick any username and password you want. This will be used when you want to connect to your database. Click Create Database User to create the user.  Atlas might create the user automatically for you if you have just created your account. In this case, the username and password will match your Atlas account credentials.  tip Make sure to remember your username and password. You will need them later. For the sake of this workshop, it might be preferable to use a simple password that you'll remember over a more secure one.  ","version":"Next","tagName":"h3"},{"title":"Manual network access configuration‚Äã","type":1,"pageTitle":"üëê Deploy a database cluster","url":"/ai-rag-lab/docs/mongodb-atlas/create-cluster#manual-network-access-configuration","content":" If you don't see a button to Allow Access from Anywhere, you should close the dialog and go to the Network Access tab under the Security section in the left sidebar. Click on the Add IP Address button, add the IP address 0.0.0.0/0 and click Confirm.  ","version":"Next","tagName":"h2"},{"title":"That's all!‚Äã","type":1,"pageTitle":"üëê Deploy a database cluster","url":"/ai-rag-lab/docs/mongodb-atlas/create-cluster#thats-all","content":" That's all! You have a new database cluster. If everything goes well, you should see your newly created cluster on the Database tab under the Deployment section.   ","version":"Next","tagName":"h2"},{"title":"üëê Get your connection string","type":0,"sectionRef":"#","url":"/ai-rag-lab/docs/mongodb-atlas/get-connection-string","content":"üëê Get your connection string In order to ingest data into your cluster later in the lab, you will need to get the connection string for your cluster. In the Atlas UI, navigate to the Overview page. In the Clusters section, select the cluster you just created and click Connect. A modal will display several ways to connect to your database. Select Drivers. Look for your connection string. It should look something like mongodb+srv://&lt;username&gt;:&lt;password&gt;@&lt;cluster-url&gt;/ Click the copy button next to your connection string to copy it to your clipboard. Paste the connection string somewhere safe. tip Don't forget to replace &lt;password&gt; with the password you set when you created the cluster.","keywords":"","version":"Next"},{"title":"üìò Semantic search in MongoDB","type":0,"sectionRef":"#","url":"/ai-rag-lab/docs/perform-semantic-search/concepts","content":"üìò Semantic search in MongoDB In MongoDB, you can semantically search through your data using MongoDB Atlas Vector Search. To perform vector search on your data in MongoDB, you need to create a vector search index. An example of a vector search index definition looks as follows: { &quot;fields&quot;:[ { &quot;type&quot;: &quot;vector&quot;, &quot;path&quot;: &quot;embedding&quot;, &quot;numDimensions&quot;: 1536, &quot;similarity&quot;: &quot;cosine&quot; }, { &quot;type&quot;: &quot;filter&quot;, &quot;path&quot;: &quot;symbol&quot; }, ... ] } In the index definition, you specify the path to the embedding field (path), the number of dimensions in the embedding vectors (numDimensions), and a similarity metric that specifies how to determine nearest neighbors (similarity). You can also index filter fields that allow you to pre-filter on certain metadata to narrow the scope of the vector search. Vector search in MongoDB takes the form of an aggregation pipeline stage. It always needs to be the first stage in the pipeline and can be followed by other stages to further process the semantic search results. An example pipeline including the $vectorSearch stage is as follows: [ { &quot;$vectorSearch&quot;: { &quot;index&quot;: &quot;vector_index&quot;, &quot;path&quot;: &quot;embedding&quot;, &quot;queryVector&quot;: [0.02421053, -0.022372592,...], &quot;numCandidates&quot;: 150, &quot;filter&quot;: {&quot;symbol&quot;: &quot;ABMD&quot;}, &quot;limit&quot;: 10 } }, { &quot;$project&quot;: { &quot;_id&quot;: 0, &quot;Content&quot;: 1, &quot;score&quot;: {&quot;$meta&quot;: &quot;vectorSearchScore&quot;} } } ] In this example, you can see a vector search query with a pre-filter. The limit field in the query definition specifies how many documents to return from the vector search. The $project stage that follows only returns documents with the Content field and the similarity score from the vector search.","keywords":"","version":"Next"},{"title":"üëê Create a vector search index","type":0,"sectionRef":"#","url":"/ai-rag-lab/docs/perform-semantic-search/create-vector-index","content":"üëê Create a vector search index To retrieve documents from MongoDB using vector search, you must configure a vector search index on the collection into which you ingested your data. The recommended way to do this is via the MongoDB drivers. Fill in any &lt;CODE_BLOCK_N&gt; placeholders and run the cells under the Step 6: Create a vector search index section in the notebook to create a vector search index. The answers for code blocks in this section are as follows: CODE_BLOCK_8 Answer collection.create_search_index(model=model) To verify that the index was created, navigate to Search Indexes for the knowledge_base collection. The index is ready to use once the status changes from PENDING to READY.","keywords":"","version":"Next"},{"title":"üëê Chunk up the data","type":0,"sectionRef":"#","url":"/ai-rag-lab/docs/prepare-the-data/chunk-data","content":"üëê Chunk up the data Since we are working with large documents, we first need to break them up into smaller chunks before embedding and storing them in MongoDB. Fill in any &lt;CODE_BLOCK_N&gt; placeholders and run the cells under the Step 3: Chunk up the data section in the notebook to chunk up the articles we loaded. The answers for code blocks in this section are as follows: CODE_BLOCK_1 Answer RecursiveCharacterTextSplitter.from_tiktoken_encoder( model_name=&quot;gpt-4&quot;, separators=separators, chunk_size=200, chunk_overlap=30 ) CODE_BLOCK_2 Answer text_splitter.split_text(text) CODE_BLOCK_3 Answer get_chunks(doc, &quot;body&quot;) ","keywords":"","version":"Next"},{"title":"üëê Perform semantic search","type":0,"sectionRef":"#","url":"/ai-rag-lab/docs/perform-semantic-search/vector-search","content":"üëê Perform semantic search Now let's run some vector search queries against our data present in MongoDB. Fill in any &lt;CODE_BLOCK_N&gt; placeholders and run the cells under the Step 7: Perform semantic search on your data section in the notebook to run vector search queries against your data. The answers for code blocks in this section are as follows: CODE_BLOCK_9 Answer get_embedding(user_query) CODE_BLOCK_10 Answer [ { &quot;$vectorSearch&quot;: { &quot;index&quot;: ATLAS_VECTOR_SEARCH_INDEX_NAME, &quot;queryVector&quot;: query_embedding, &quot;path&quot;: &quot;embedding&quot;, &quot;numCandidates&quot;: 150, &quot;limit&quot;: 5 } }, { &quot;$project&quot;: { &quot;_id&quot;: 0, &quot;body&quot;: 1, &quot;score&quot;: {&quot;$meta&quot;: &quot;vectorSearchScore&quot;} } } ] CODE_BLOCK_11 Answer collection.aggregate(pipeline) ","keywords":"","version":"Next"},{"title":"üëê Ingest data into MongoDB","type":0,"sectionRef":"#","url":"/ai-rag-lab/docs/prepare-the-data/ingest-data","content":"üëê Ingest data into MongoDB The final step to build a MongoDB vector store for our RAG application is to ingest the embedded article chunks into MongoDB. Fill in any &lt;CODE_BLOCK_N&gt; placeholders and run the cells under the Step 5: Ingest data into MongoDB section in the notebook to ingest the embedded documents into MongoDB. The answers for code blocks in this section are as follows: CODE_BLOCK_6 Answer mongodb_client[DB_NAME][COLLECTION_NAME] CODE_BLOCK_7 Answer collection.insert_many(embedded_docs) To verify that the data has been imported into your MongoDB cluster, navigate to the Overview page in the Atlas UI. In the Clusters section, select your cluster and click Browse collections. Ensure that you see a database called mongodb_rag_lab, and a collection named knowledge_base under it. Note the number and format of documents in the collection.","keywords":"","version":"Next"},{"title":"üëê Load the dataset","type":0,"sectionRef":"#","url":"/ai-rag-lab/docs/prepare-the-data/load-data","content":"üëê Load the dataset First, let's download the dataset for our lab. We'll use a subset of articles from the MongoDB Developer Center as the source data for our RAG application. Run all the cells under the Step 2: Load the dataset section in the notebook to load the articles as a list of Python objects consisting of the content and relevant metadata.","keywords":"","version":"Next"},{"title":"üëê Generate embeddings","type":0,"sectionRef":"#","url":"/ai-rag-lab/docs/prepare-the-data/embed-data","content":"üëê Generate embeddings To perform vector search on our data, we need to embed it (i.e. generate embedding vectors) before ingesting it into MongoDB. Fill in any &lt;CODE_BLOCK_N&gt; placeholders and run the cells under the Step 4: Generate embeddings section in the notebook to embed the chunked articles. The answers for code blocks in this section are as follows: CODE_BLOCK_4 Answer embedding_model.encode(text) CODE_BLOCK_5 Answer doc[&quot;embedding&quot;] = get_embedding(doc[&quot;body&quot;]) caution If the embedding generation is taking too long (&gt; 5 min), kill/interrupt the cell and move on to the next step with the documents that have been embedded up until that point.","keywords":"","version":"Next"},{"title":"üìò Components of a RAG system","type":0,"sectionRef":"#","url":"/ai-rag-lab/docs/rag/components-of-rag","content":"","keywords":"","version":"Next"},{"title":"Retrieval‚Äã","type":1,"pageTitle":"üìò Components of a RAG system","url":"/ai-rag-lab/docs/rag/components-of-rag#retrieval","content":" Retrieval mainly involves processing your data and constructing a knowledge base in a way that you are able to efficiently retrieve relevant information from it. It typically involves three main steps:  Chunking: Break down large pieces of information into smaller segments or chunks. Embedding: Convert a piece of information such as text, images, audio, video, etc. into an array of numbers a.k.a. vectors. Semantic Search: Retrieve the most relevant documents from the knowledge base based on embedding similarity with the query vector.  ","version":"Next","tagName":"h2"},{"title":"Generation‚Äã","type":1,"pageTitle":"üìò Components of a RAG system","url":"/ai-rag-lab/docs/rag/components-of-rag#generation","content":" Generation involves crafting a prompt that contains all the instructions and information required by the LLM to generate accurate answers to user queries. ","version":"Next","tagName":"h2"},{"title":"üìò What is RAG?","type":0,"sectionRef":"#","url":"/ai-rag-lab/docs/rag/what-is-rag","content":"üìò What is RAG? RAG, short for Retrieval Augmented Generation, is a technique to enhance the quality of responses generated by a large language model (LLM), by augmenting its pre-trained knowledge with information retrieved from external sources. This results is more accurate responses from the LLM by grounding them in real, contextually relevant data.","keywords":"","version":"Next"},{"title":"üìò When to use RAG?","type":0,"sectionRef":"#","url":"/ai-rag-lab/docs/rag/rag-usecases","content":"üìò When to use RAG? RAG is best suited for the following: Tasks that require very specific information that you don‚Äôt think will be present in the LLMs parametric knowledge i.e. information that is not widely available on the internetTasks that require information from multiple different data sourcesTasks that involve basic question-answering or summarization on a piece of information Do not expect success on complex multi-step tasks involving deductive reasoning or long-term planning. These are more suited for agentic workflows. Here are some examples of tasks/questions that DO NOT require or cannot be achieved with RAG: Who was the first president of the United States? The information required to answer this question is very likely present in the parametric knowledge of most LLMs. Hence, this question can be answered using a simple prompt to an LLM. How has the trend in the average daily calorie intake among adults changed over the last decade in the United States, and what impact might this have on obesity rates? Additionally, can you provide a graphical representation of the trend in obesity rates over this period? This question involves multiple sub-tasks such as data aggregation, visualization, and reasoning. Hence, this is a good use case for an AI agent rather than RAG. Here are some use cases for RAG: What is the travel reimbursement policy for meals for my company? The information required to answer this question is most likely not present in the parametric knowledge of available LLMs. However, this question can easily be answered using RAG on a knowledge base consisting of your company's data. Hi, I'm having trouble installing your software on my Windows 10 computer. It keeps giving me an error message saying 'Installation failed: Error code 1234'. How can I resolve this issue? Again, this question requires troubleshooting information for a specific software, the documentation for which might not be widely available, but can be solved using RAG.","keywords":"","version":"Next"},{"title":"ü¶π Combine pre-filtering with vector search","type":0,"sectionRef":"#","url":"/ai-rag-lab/docs/perform-semantic-search/pre-filtering","content":"ü¶π Combine pre-filtering with vector search Pre-filtering is a technique to optimize vector search by only considering documents that match certain criteria during vector search. In this section, you will learn how to combine filters with vector search. This mainly involves: Updating the vector search index to include the appropriate filter fieldsUpdating the $vectorSearch stage in the aggregation pipeline definition to include the filters Fill in any &lt;CODE_BLOCK_N&gt; placeholders and run the cells under the ü¶π‚Äç‚ôÄÔ∏è Combine pre-filtering with vector search section in the notebook to experiment with combining pre-filters with your vector search queries. The answers for code blocks in this section are as follows: CODE_BLOCK_12 Answer { &quot;name&quot;: ATLAS_VECTOR_SEARCH_INDEX_NAME, &quot;type&quot;: &quot;vectorSearch&quot;, &quot;definition&quot;: { &quot;fields&quot;: [ { &quot;type&quot;: &quot;vector&quot;, &quot;path&quot;: &quot;embedding&quot;, &quot;numDimensions&quot;: 384, &quot;similarity&quot;: &quot;cosine&quot; }, {&quot;type&quot;: &quot;filter&quot;, &quot;path&quot;: &quot;metadata.contentType&quot;} ] } } CODE_BLOCK_13 Answer [ { &quot;$vectorSearch&quot;: { &quot;index&quot;: ATLAS_VECTOR_SEARCH_INDEX_NAME, &quot;path&quot;: &quot;embedding&quot;, &quot;queryVector&quot;: query_embedding, &quot;numCandidates&quot;: 150, &quot;limit&quot;: 5, &quot;filter&quot;: {&quot;metadata.contentType&quot;: &quot;Video&quot;} } }, { &quot;$project&quot;: { &quot;_id&quot;: 0, &quot;body&quot;: 1, &quot;score&quot;: {&quot;$meta&quot;: &quot;vectorSearchScore&quot;} } } ] CODE_BLOCK_14 Answer { &quot;name&quot;: ATLAS_VECTOR_SEARCH_INDEX_NAME, &quot;type&quot;: &quot;vectorSearch&quot;, &quot;definition&quot;: { &quot;fields&quot;: [ { &quot;type&quot;: &quot;vector&quot;, &quot;path&quot;: &quot;embedding&quot;, &quot;numDimensions&quot;: 384, &quot;similarity&quot;: &quot;cosine&quot; }, {&quot;type&quot;: &quot;filter&quot;, &quot;path&quot;: &quot;metadata.contentType&quot;}, {&quot;type&quot;: &quot;filter&quot;, &quot;path&quot;: &quot;updated&quot;} ] } } CODE_BLOCK_15 Answer [ { &quot;$vectorSearch&quot;: { &quot;index&quot;: ATLAS_VECTOR_SEARCH_INDEX_NAME, &quot;path&quot;: &quot;embedding&quot;, &quot;queryVector&quot;: query_embedding, &quot;numCandidates&quot;: 150, &quot;limit&quot;: 5, &quot;filter&quot;: { &quot;$and&quot;: [ {&quot;metadata.contentType&quot;: &quot;Tutorial&quot;}, {&quot;updated&quot;: {&quot;$gte&quot;: &quot;2024-05-19&quot;}} ] } } }, { &quot;$project&quot;: { &quot;_id&quot;: 0, &quot;body&quot;: 1, &quot;updated&quot;: 1, &quot;score&quot;: {&quot;$meta&quot;: &quot;vectorSearchScore&quot;} } } ] ","keywords":"","version":"Next"},{"title":"üéØ Summary","type":0,"sectionRef":"#","url":"/ai-rag-lab/docs/summary","content":"üéØ Summary Congratulations! Following this lab, you have successfully: learned what is Retrieval Augmented Generation a.k.a. RAGlearned when to use RAGlearned how to perform semantic search against data in MongoDBbuilt a RAG applicationadded memory to your RAG application Here are some resources that you might find helpful: MongoDB Developer CenterGenAI Code Examples RepositoryGenAI Community Forums","keywords":"","version":"Next"}],"options":{"id":"default"}}